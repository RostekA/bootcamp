{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "### Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat(\"Dane/ALLAML.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['X']\n",
    "y = data['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((72, 7129), (72, 1))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y[:, 0]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7119</th>\n",
       "      <th>7120</th>\n",
       "      <th>7121</th>\n",
       "      <th>7122</th>\n",
       "      <th>7123</th>\n",
       "      <th>7124</th>\n",
       "      <th>7125</th>\n",
       "      <th>7126</th>\n",
       "      <th>7127</th>\n",
       "      <th>7128</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.017172</td>\n",
       "      <td>0.074113</td>\n",
       "      <td>-0.406939</td>\n",
       "      <td>-0.905824</td>\n",
       "      <td>-0.341244</td>\n",
       "      <td>-1.077075</td>\n",
       "      <td>0.926511</td>\n",
       "      <td>0.147111</td>\n",
       "      <td>1.922802</td>\n",
       "      <td>0.474334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102543</td>\n",
       "      <td>-0.514763</td>\n",
       "      <td>-1.295717</td>\n",
       "      <td>0.019007</td>\n",
       "      <td>-0.064038</td>\n",
       "      <td>0.027578</td>\n",
       "      <td>0.121334</td>\n",
       "      <td>0.588985</td>\n",
       "      <td>-0.388650</td>\n",
       "      <td>-0.159994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.249817</td>\n",
       "      <td>0.906262</td>\n",
       "      <td>0.057617</td>\n",
       "      <td>0.837052</td>\n",
       "      <td>-0.087528</td>\n",
       "      <td>-0.025783</td>\n",
       "      <td>-0.931584</td>\n",
       "      <td>0.227202</td>\n",
       "      <td>0.233942</td>\n",
       "      <td>-0.106453</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067427</td>\n",
       "      <td>0.551561</td>\n",
       "      <td>-0.277449</td>\n",
       "      <td>0.159027</td>\n",
       "      <td>0.320191</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>-0.043314</td>\n",
       "      <td>0.031879</td>\n",
       "      <td>-0.572969</td>\n",
       "      <td>0.412253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.394762</td>\n",
       "      <td>1.155907</td>\n",
       "      <td>-2.436312</td>\n",
       "      <td>1.069436</td>\n",
       "      <td>-1.004181</td>\n",
       "      <td>-1.689219</td>\n",
       "      <td>0.343441</td>\n",
       "      <td>-1.765056</td>\n",
       "      <td>1.408315</td>\n",
       "      <td>-1.378024</td>\n",
       "      <td>...</td>\n",
       "      <td>1.483553</td>\n",
       "      <td>1.735638</td>\n",
       "      <td>0.511994</td>\n",
       "      <td>-0.564852</td>\n",
       "      <td>1.645782</td>\n",
       "      <td>0.792121</td>\n",
       "      <td>2.290824</td>\n",
       "      <td>0.700407</td>\n",
       "      <td>-0.329348</td>\n",
       "      <td>-0.259515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.208891</td>\n",
       "      <td>0.479786</td>\n",
       "      <td>2.225541</td>\n",
       "      <td>-1.585099</td>\n",
       "      <td>-1.356110</td>\n",
       "      <td>-1.256726</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>-0.623763</td>\n",
       "      <td>-0.347652</td>\n",
       "      <td>-0.295649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686816</td>\n",
       "      <td>0.545019</td>\n",
       "      <td>2.628618</td>\n",
       "      <td>-0.549001</td>\n",
       "      <td>-1.466475</td>\n",
       "      <td>-0.340289</td>\n",
       "      <td>-0.648641</td>\n",
       "      <td>-1.327461</td>\n",
       "      <td>-0.492831</td>\n",
       "      <td>-1.503531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.087820</td>\n",
       "      <td>0.365365</td>\n",
       "      <td>-0.553640</td>\n",
       "      <td>-0.190798</td>\n",
       "      <td>0.190742</td>\n",
       "      <td>0.746051</td>\n",
       "      <td>0.241580</td>\n",
       "      <td>0.687724</td>\n",
       "      <td>-0.112777</td>\n",
       "      <td>0.676729</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.205528</td>\n",
       "      <td>-0.063374</td>\n",
       "      <td>0.786583</td>\n",
       "      <td>0.322825</td>\n",
       "      <td>0.147288</td>\n",
       "      <td>-1.175747</td>\n",
       "      <td>0.048695</td>\n",
       "      <td>0.098732</td>\n",
       "      <td>-0.605025</td>\n",
       "      <td>0.138569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0 -1.017172  0.074113 -0.406939 -0.905824 -0.341244 -1.077075  0.926511   \n",
       "1 -0.249817  0.906262  0.057617  0.837052 -0.087528 -0.025783 -0.931584   \n",
       "2  0.394762  1.155907 -2.436312  1.069436 -1.004181 -1.689219  0.343441   \n",
       "3 -0.208891  0.479786  2.225541 -1.585099 -1.356110 -1.256726  0.782500   \n",
       "4  0.087820  0.365365 -0.553640 -0.190798  0.190742  0.746051  0.241580   \n",
       "\n",
       "       7         8         9     ...      7119      7120      7121      7122  \\\n",
       "0  0.147111  1.922802  0.474334  ...  0.102543 -0.514763 -1.295717  0.019007   \n",
       "1  0.227202  0.233942 -0.106453  ... -0.067427  0.551561 -0.277449  0.159027   \n",
       "2 -1.765056  1.408315 -1.378024  ...  1.483553  1.735638  0.511994 -0.564852   \n",
       "3 -0.623763 -0.347652 -0.295649  ...  0.686816  0.545019  2.628618 -0.549001   \n",
       "4  0.687724 -0.112777  0.676729  ... -0.205528 -0.063374  0.786583  0.322825   \n",
       "\n",
       "       7123      7124      7125      7126      7127      7128  \n",
       "0 -0.064038  0.027578  0.121334  0.588985 -0.388650 -0.159994  \n",
       "1  0.320191  0.003201 -0.043314  0.031879 -0.572969  0.412253  \n",
       "2  1.645782  0.792121  2.290824  0.700407 -0.329348 -0.259515  \n",
       "3 -1.466475 -0.340289 -0.648641 -1.327461 -0.492831 -1.503531  \n",
       "4  0.147288 -1.175747  0.048695  0.098732 -0.605025  0.138569  \n",
       "\n",
       "[5 rows x 7129 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2], dtype=uint8), array([47, 25], dtype=int64))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance without Feature Selection\n",
    "\n",
    "* curse of dimensionality\n",
    "* features without predictive power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LogisticRegression(), LinearSVC(), DecisionTreeClassifier(), RandomForestClassifier()]\n",
    "names = ['LR', 'SVC', 'DT', 'RF']\n",
    "\n",
    "basic_acc = {}\n",
    "for m, n in zip(models, names):\n",
    "    basic_acc[n] = round(cross_val_score(m,X,y,cv=10).mean(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': 0.957, 'SVC': 0.805, 'DT': 0.864, 'RF': 0.961}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Regularization\n",
    "* training with feature selection involved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty=\"l1\", solver='saga', random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(penalty=&#x27;l1&#x27;, random_state=100, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(penalty=&#x27;l1&#x27;, random_state=100, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(penalty='l1', random_state=100, solver='saga')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.00838421,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0008577572039006268,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0014395380743701567,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.002924525769682889,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0008658072167149049,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0008310409931659088,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0016953789976246218,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00035618616256119875,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0028394091091790935,\n",
       " -0.0022297889587205807,\n",
       " -0.004420536750401285,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0024667755668649205,\n",
       " 0.004608224952840143,\n",
       " 0.0033811696370697514,\n",
       " -0.000847886953843857,\n",
       " -0.0021710162970285537,\n",
       " 0.0,\n",
       " -0.00010276276599723449,\n",
       " 0.0011794090534744473,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -4.76214768384677e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -6.046368406995294e-05,\n",
       " 0.0,\n",
       " -0.0008287501626951421,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0016415170063649978,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.011415049374265381,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0021999354164133835,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0073056749224517355,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.00017398965634498847,\n",
       " 0.0,\n",
       " 0.00041653944364703724,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.006786358722850597,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.004372384475333505,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.004457497389561194,\n",
       " -0.006253107934941929,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0001461506439961542,\n",
       " -0.010240287697734227,\n",
       " -0.004912248238529846,\n",
       " 0.00047774340556066403,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.009437478586309125,\n",
       " -0.0008051398367813661,\n",
       " 0.0,\n",
       " -0.003395284389699456,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.00455417370419291,\n",
       " -0.0013958891816240728,\n",
       " -0.0013911922970661285,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0074070288004694515,\n",
       " 0.0071653015239129475,\n",
       " 0.0,\n",
       " 0.0007526836263645194,\n",
       " 0.0,\n",
       " 0.0020609004368109356,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0020404646416129282,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.011937719542264214,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.004260031473155707,\n",
       " 0.0,\n",
       " 0.003815155209714033,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.003147909828491364,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.005696527926442839,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.006137373932580082,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0008887913476159739,\n",
       " -0.0003588240052485554,\n",
       " -0.0023368652283823716,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.014799706414913034,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.004635941250104117,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0019594985001894906,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0027899004135882913,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.006593184784036937,\n",
       " 0.012939175260232368,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.004188757272895717,\n",
       " 0.005832433536374825,\n",
       " 0.0,\n",
       " 0.006238593612101091,\n",
       " -0.0005822388692390297,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.005027430066964954,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.007572743827086127,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -5.9893874950843714e-05,\n",
       " -0.0013294000040435208,\n",
       " 0.0,\n",
       " 0.003015164940886413,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0042541333382244036,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00989748019041512,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0028549959137333884,\n",
       " 0.0,\n",
       " -0.002377097632151484,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.002321114173400417,\n",
       " -0.004170879605926267,\n",
       " 0.00680877925077947,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00010083401310991436,\n",
       " 0.0,\n",
       " 0.003237667880359196,\n",
       " 0.0,\n",
       " 0.012424769220711437,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -6.36573129749091e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.004325932937056469,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00781956382974897,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0003770781903927994,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.017071600396921658,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.010465817454813744,\n",
       " 0.0,\n",
       " -0.005762793509461362,\n",
       " -0.005004086194843219,\n",
       " -0.010133029702386593,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.003448027837735497,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.002455538532350609,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -4.586683649381725e-05,\n",
       " -0.00827189689559164,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.005521182955581299,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0022286267816557137,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.003456415783469875,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0059921178894310765,\n",
       " 0.0,\n",
       " -0.001708928910473513,\n",
       " 0.0020273863761806803,\n",
       " -0.008172611000620575,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.003364797271173687,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.004999721079171803,\n",
       " -0.004116787263974885,\n",
       " -0.0019088788913912444,\n",
       " -0.002205995888574415,\n",
       " 0.006883832084348883,\n",
       " -0.014318363735054136,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.004627411671296319,\n",
       " 0.0,\n",
       " -0.0016206286757917121,\n",
       " 0.0,\n",
       " -0.0031455496918726656,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.00031940714165046324,\n",
       " -0.001039782311632324,\n",
       " 0.0,\n",
       " 0.002966344833591949,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.013330064305677996,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0041208666816012875,\n",
       " 0.0,\n",
       " 0.019025828261617764,\n",
       " 0.0,\n",
       " -0.0029280084815637734,\n",
       " 0.002316747480659861,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0020016805009923236,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0034517581094188677,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.004442256842233377,\n",
       " 0.0,\n",
       " -0.0007181441606881746,\n",
       " 0.000560245734969364,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.011644228275442408,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0014762847519185717,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0017760065735544553,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.002457984180696057,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.005043616068531738,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.006625626393949045,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.010121324777743336,\n",
       " -0.00035266667376718675,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.004335880735665475,\n",
       " -0.0018315801551110587,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.002251985101743586,\n",
       " 0.0,\n",
       " -0.0004127991928339947,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0002584144564774395,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.004976170150477251,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.004813491506830689,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.007116252275434614,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0029056744148098874,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0037922065337576806,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0029175270576060554,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.002546784239245257,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0034064227995264894,\n",
       " 0.0,\n",
       " -0.0011992978157646355,\n",
       " -0.005438502183586207,\n",
       " 0.0,\n",
       " -0.001045364146452527,\n",
       " 0.0,\n",
       " -0.0021821375477262266,\n",
       " -0.0027038429867499458,\n",
       " -0.00013204194050045207,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.006802514754510734,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.00789432896634677,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.007860856692947775,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.00024162388456049075,\n",
       " -0.0021400479534562132,\n",
       " 0.0,\n",
       " 0.0021387420603620495,\n",
       " -0.007527049329329133,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.001388971171501915,\n",
       " 0.0,\n",
       " 0.0013623934789055532,\n",
       " 0.0,\n",
       " 0.0005344263285378836,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.008150487793905606,\n",
       " -0.00011778099222116573,\n",
       " -0.0032287035881891782,\n",
       " 0.000307662101562628,\n",
       " -0.00220966617195788,\n",
       " 0.0,\n",
       " -0.001521708660956062,\n",
       " 0.0007935639548686774,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0039060881786900543,\n",
       " 0.0014762551210115338,\n",
       " 0.006876803075275517,\n",
       " 0.0,\n",
       " -0.0013711434449054005,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.008959460744496548,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.007436943366549436,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0023433466578724224,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.005275084215192084,\n",
       " 0.0,\n",
       " -0.0023909857091010647,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.011564276845890611,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0006209790412432842,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.003309508162156401,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.004868915325242448,\n",
       " 0.0,\n",
       " -5.6621905570464494e-05,\n",
       " 0.0,\n",
       " -0.008957572303661088,\n",
       " 0.0,\n",
       " 0.014655796067722635,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.013512647029022707,\n",
       " 0.0,\n",
       " -0.001620650032609627,\n",
       " 0.0,\n",
       " 0.014620700936028797,\n",
       " 0.0018815306152010092,\n",
       " -5.825334442801475e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.006598241354931825,\n",
       " 0.0,\n",
       " -0.0015949986121804975,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.007997057412788305,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.001269833002852548,\n",
       " -0.008113247088287437,\n",
       " 0.000728779356443139,\n",
       " 0.0009967080458700586,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.014582867492172356,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0016712960917785408,\n",
       " 0.004320773739642741,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00467604976022165,\n",
       " 0.00449812249770275,\n",
       " 0.0,\n",
       " -0.004961487633378392,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0016407796012555672,\n",
       " 0.00491190812673008,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.00226478961766255,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0007266362754106565,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.001817331824334725,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.008641704073425684,\n",
       " 0.0,\n",
       " -0.001924434460761748,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.004934849245484059,\n",
       " 0.0,\n",
       " 0.009036867833793694,\n",
       " 0.0,\n",
       " 0.0006012484280462045,\n",
       " 0.0,\n",
       " -0.00535683032091369,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0003234645536347986,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0027435621746676963,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0014116492155121737,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.010475296024876596,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0005882750456362679,\n",
       " 0.003394159459879707,\n",
       " 0.0,\n",
       " 0.009668164374600028,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.003843494899305744,\n",
       " 0.0,\n",
       " 0.00025626626808457093,\n",
       " -0.00027247456173965044,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.00064498532153349,\n",
       " 0.0,\n",
       " -0.0011067973671656693,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.011327325372904018,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0110947683074344,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.001802588574342204,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.013132851952076302,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0001829366220186225,\n",
       " 0.0,\n",
       " 0.007389241363113979,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.001551028068874528,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.00425401978250208,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0037774364772571803,\n",
       " 0.0009535685691714233,\n",
       " 0.0015568292470203259,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.00457098890663619,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.003888480549210961,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0003030173097091619,\n",
       " ...]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7129"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.coef_[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1884"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(model.coef_ != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9428571428571428"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model, X, y, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearSVC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714285714285715"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dual must be False when L1\n",
    "np.mean(cross_val_score(LinearSVC(penalty=\"l1\", dual=False, random_state=100), X, y, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': 0.957, 'SVC': 0.805, 'DT': 0.864, 'RF': 0.961}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 feature selection as a separate step in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "?SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold - automatically to 1e-5\n",
    "model = LogisticRegression(\"l1\", solver='saga', random_state=100)\n",
    "selector = SelectFromModel(model)\n",
    "\n",
    "X_tr = selector.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 1881)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714285714285715"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(\n",
    "    SelectFromModel(LogisticRegression(\"l1\", solver='saga')), # choose features using LR\n",
    "    LogisticRegression() # models the selected features \n",
    ")\n",
    "\n",
    "cross_val_score(pipeline,X,y,cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8357142857142857"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(SelectFromModel(LogisticRegression(\"l1\", solver='saga')),\n",
    "                          DecisionTreeClassifier())\n",
    "\n",
    "cross_val_score(pipeline,X,y,cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': 0.957, 'SVC': 0.805, 'DT': 0.864, 'RF': 0.961}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faeature Selection based on coefficients magnitude\n",
    "* make sens only when data are scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold - instead of deafault 1e-5, we set it to 0.01 based on the coefficients distribution\n",
    "# ?SelectFromModel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00643273, -0.00542242,  0.00035208, ..., -0.00194702,\n",
       "         0.01586228, -0.00226332]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression().fit(X,y).coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(LogisticRegression().fit(X,y).coef_[0], bins=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9857142857142858"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(SelectFromModel(LogisticRegression(),threshold=0.01),\n",
    "                          LogisticRegression())\n",
    "\n",
    "cross_val_score(pipeline,scale(X), y, cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection using Features Importance\n",
    "* applicable for tree-based algorithms (decision tree, random forest etc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.0599445 , 0.82692948, 0.11312602])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(dt.feature_importances_))\n",
    "dt.feature_importances_[dt.feature_importances_>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8892857142857142"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(SelectFromModel(DecisionTreeClassifier(),threshold=0.01),\n",
    "                          LogisticRegression())\n",
    "\n",
    "cross_val_score(pipeline,scale(X),y,cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(SelectFromModel(DecisionTreeClassifier(),threshold=0.01),\n",
    "                          DecisionTreeClassifier())\n",
    "\n",
    "cross_val_score(pipeline,scale(X),y,cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': 0.957, 'SVC': 0.805, 'DT': 0.864, 'RF': 0.961}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 3)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SelectFromModel(DecisionTreeClassifier(),threshold=0.01).fit_transform(X,y).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "* one of the best method for feature selection\n",
    "* based on averaged results from many trees\n",
    "* the number of trees should be large (more than 100) for effective results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345, 153, 10)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi = RandomForestClassifier(100).fit(X,y).feature_importances_\n",
    "len(fi[fi>0]), len(fi[fi>0.002]), len(fi[fi>0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714285714285715"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(SelectFromModel(RandomForestClassifier(100),threshold=0.002),\n",
    "                          LogisticRegression())\n",
    "\n",
    "cross_val_score(pipeline,scale(X),y,cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': 0.957, 'SVC': 0.805, 'DT': 0.864, 'RF': 0.961}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination\n",
    "* iterative process of removing the least important features\n",
    "* takes into consideration the cumulative impact of the features (compared to filter-based approach which is univariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE, RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "?RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6929 features.\n",
      "Fitting estimator with 6729 features.\n",
      "Fitting estimator with 6529 features.\n",
      "Fitting estimator with 6329 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5929 features.\n",
      "Fitting estimator with 5729 features.\n",
      "Fitting estimator with 5529 features.\n",
      "Fitting estimator with 5329 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4929 features.\n",
      "Fitting estimator with 4729 features.\n",
      "Fitting estimator with 4529 features.\n",
      "Fitting estimator with 4329 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3929 features.\n",
      "Fitting estimator with 3729 features.\n",
      "Fitting estimator with 3529 features.\n",
      "Fitting estimator with 3329 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2929 features.\n",
      "Fitting estimator with 2729 features.\n",
      "Fitting estimator with 2529 features.\n",
      "Fitting estimator with 2329 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1929 features.\n",
      "Fitting estimator with 1729 features.\n",
      "Fitting estimator with 1529 features.\n",
      "Fitting estimator with 1329 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 929 features.\n",
      "Fitting estimator with 729 features.\n",
      "Fitting estimator with 529 features.\n",
      "Fitting estimator with 329 features.\n",
      "Fitting estimator with 129 features.\n"
     ]
    }
   ],
   "source": [
    "# we can have at least 100 features; during each iteration, 200 are removed\n",
    "selector = RFE(LogisticRegression(), n_features_to_select=100, step=200, verbose=1)\n",
    "selected_features = selector.fit_transform(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 100)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(selector.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'C']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the names of features (if our X is df)\n",
    "features_names = ['A', 'B', 'C']\n",
    "features_flags = [True, False, True]\n",
    "\n",
    "[feat for feat, flag in zip(features_names, features_flags) if flag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select indices of features\n",
    "[i for i, x in enumerate(features_flags) if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(features_flags)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9571428571428571"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(RFE(LogisticRegression(), n_features_to_select=100, step=200),\n",
    "                          LogisticRegression())\n",
    "\n",
    "cross_val_score(pipeline, scale(X), y, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8446428571428571"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(RFE(DecisionTreeClassifier(), n_features_to_select=100, step=200),\n",
    "                          LogisticRegression())\n",
    "\n",
    "cross_val_score(pipeline, scale(X), y, cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is better to use the same type of algo for feature selection as for model training. However, technically it is possible to use different ones. \n",
    "\n",
    "### RFECV - automatically select the number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFECV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFECV(cv=3, estimator=LogisticRegression(), step=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFECV</label><div class=\"sk-toggleable__content\"><pre>RFECV(cv=3, estimator=LogisticRegression(), step=50)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFECV(cv=3, estimator=LogisticRegression(), step=50)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector = RFECV(LogisticRegression(), cv=3, step=50)\n",
    "selector.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n",
      "Fitting estimator with 1129 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 7129 features.\n",
      "Fitting estimator with 6629 features.\n",
      "Fitting estimator with 6129 features.\n",
      "Fitting estimator with 5629 features.\n",
      "Fitting estimator with 5129 features.\n",
      "Fitting estimator with 4629 features.\n",
      "Fitting estimator with 4129 features.\n",
      "Fitting estimator with 3629 features.\n",
      "Fitting estimator with 3129 features.\n",
      "Fitting estimator with 2629 features.\n",
      "Fitting estimator with 2129 features.\n",
      "Fitting estimator with 1629 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9857142857142858"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(RFECV(LogisticRegression(),cv=5,step=500, verbose=1),\n",
    "                          LogisticRegression())\n",
    "\n",
    "cross_val_score(pipeline,scale(X),y,cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter-based Feature Selection\n",
    "Sample filters:\n",
    "\n",
    "1. Correlation between $Y$ and  $X$.\n",
    "\n",
    "2. Mutual information between $X$ and $Y$:\n",
    "\n",
    "$ I(X,Y) = H(Y) - H(Y | X)$,\n",
    "\n",
    "where\n",
    "\n",
    "$H(Y)$ - entropy of $Y$,\n",
    "\n",
    "$H(Y|X)$ - entropy of $Y$, with known $X$ (conditional entropy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SelectKBest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info_classif?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(SelectKBest(mutual_info_classif, k=100),\n",
    "                          LogisticRegression())\n",
    "\n",
    "cross_val_score(pipeline, scale(X), y, cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "For the given dataset, check different feature selection methods and different algorithms. Select the combination with highest perfomance.\n",
    "\n",
    "__Algorithms to check__: \n",
    "* Logistic Regression, \n",
    "* Decision Tree, \n",
    "* Random Forest\n",
    "\n",
    "__Methods__: \n",
    "* L1 regularization;\n",
    "* feature importance based;\n",
    "* RFE (with automatic selection is OK)\n",
    "* filter based\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dane/FS_test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target', axis=1)\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_score,\\\n",
    "recall_score, precision_recall_curve, f1_score, confusion_matrix, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, y = make_classification(n_features=2, n_informative=2, n_redundant=0, n_classes=2, weights=[0.92, 0.08],\\\n",
    "                           random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why accuracy is not enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X, y)\n",
    "lr.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(predictions, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(predictions, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(predictions, y), index=['Pred 0', 'Pred 1'], columns=['Actual 0', 'Actual 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame([predictions, y]).T\n",
    "a.columns = ['Predict', 'Actual']\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall\n",
    "* of all positive cases (class 1), how many we have detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_df = a[a.Actual==1]\n",
    "recall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = recall_df.Predict.sum() / recall_df.Actual.sum()\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision\n",
    "* of what we have predicted as positive case (class 1), how many cases are really positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_df = a[a.Predict==1]\n",
    "precision_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_df.Actual.sum() / precision_df.Predict.sum()\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-1 Score\n",
    "* harmonic average of precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(predictions, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC curve\n",
    "* False Positive Rate (FPR)\n",
    "* True Positive Rate (TPR)\n",
    "* AUC - area under curve => the higher, the better; max value = 1.\n",
    "* $gini = 2 * AUC - 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predcitions_proba = lr.predict_proba(X)\n",
    "predcitions_proba[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc_curve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y\n",
    "y_score = predcitions_proba[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false positive rate, true positive rate and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# area under curve\n",
    "roc_auc = roc_auc_score(y_true, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr, label = f\"AUC = {roc_auc : .2f}\")\n",
    "plt.title(\"ROC\")\n",
    "plt.xlabel(\"False Posititve Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall_curve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, _ = precision_recall_curve(y_true, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(r, p)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc(r, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Summary:\n",
    "* accuracy is not the best metrics for imbalanced data;\n",
    "* precision and recall may be useful in case of immablanced data;\n",
    "* ROC curve is better for balanced data whereas precision-recall curve is better for imbalanced;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "For the given dataset __metrics_test.csv__, conduct classification using two algorithms:\n",
    "* Logistic Regression\n",
    "* Decision Tree\n",
    "\n",
    "Compare their performance using __accuracy, precision, recall, F-1 and ROC__. Which model would you choose and why?\n",
    "\n",
    "__Note__: \n",
    "1. the last column in the dataset is the target\n",
    "2. it is worth to use dummy classifier first to understanf its baseline accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import make_classification\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# X, y = make_classification(n_samples=200, n_features=10, n_informative=6, n_redundant=4, n_classes=2, weights=[0.80, 0.20],\\\n",
    "#                            random_state=123)\n",
    "\n",
    "# y = y.reshape(-1, 1)\n",
    "# pd.DataFrame(np.concatenate((X, y), axis=1)).to_csv(\"metrics_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dane/metrics_test.csv\")\n",
    "\n",
    "X = df.drop('10', axis=1)\n",
    "y = df['10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_preds = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_acc = lr.score(X_test, y_test)\n",
    "lr_precision = precision_score(y_test, lr_preds)\n",
    "lr_recall = recall_score(y_test, lr_preds)\n",
    "lr_f1 = f1_score(y_test, lr_preds)\n",
    "\n",
    "print(lr_acc, lr_precision, lr_recall, lr_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'name': 'Ros Apostol', \n",
    "#  'age': 32,\n",
    "#  'in_love_with_ML_from': 2016,\n",
    "#  'city': 'Krakow', \n",
    "#  'jobs': [\n",
    "#      {'Schlumberger': 'Data Science Tech Lead'},\n",
    "#      {'Sages': 'Data Science Trainer'}\n",
    "#  ], \n",
    "#  'certificates': [\n",
    "#      {'AWS': ['Machine Learning Specilaty']},\n",
    "#      {'Azure': ['Azure Data Scientist', 'Azure AI Engineer']}\n",
    "#  ], \n",
    "#  'hobbies': ['data science & MLOps', \n",
    "#              'philosophy & theology',\n",
    "#              'foreign languages', \n",
    "#              'traveling'], \n",
    "#  'LinkedIn': 'https://www.linkedin.com/in/apostolros/',\n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
